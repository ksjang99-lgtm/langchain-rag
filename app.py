import hashlib
import streamlit as st

from config import load_settings
from clients import get_openai_client
from ocr_service import extract_text_from_image_gpt41mini
from ingest_service import ingest_pdf_to_supabase
from retrieval_service import retrieve_contexts, list_docs, get_page_image_url
from answer_service import openai_answer_with_rag
from storage_service import delete_doc_and_assets
from utils_text import is_refusal_answer, merge_pages_cited_then_search
from PIL import Image
from io import BytesIO  # âœ… ì¶”ê°€

from audio_recorder_streamlit import audio_recorder
import os
import tempfile
from process_rag_query import process_rag_query
from render import render_related_pages, get_related_pages

st.set_page_config(page_title="NexOps-ê°€ì¥ ëª…í™•í•œ ê·¼ê±°, ê°€ì¥ ë¹ ë¥¸ í˜„ì¥ ì¡°ì¹˜", layout="wide")
settings = load_settings()

st.title("ğŸ›¡ï¸ NexOps for Security")

if not settings.openai_api_key or not settings.supabase_url or not settings.supabase_service_key:
    st.warning(
        "í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤!\n\n"
        "- OPENAI_API_KEY\n"
        "- SUPABASE_URL\n"
        "- SUPABASE_SERVICE_ROLE_KEY\n"
    )
    st.stop()

mode = st.sidebar.radio("ë©”ë‰´", ["AI í˜„ì¥ ê°€ì´ë“œ", "ì§€ì‹ ìì‚° ê´€ë¦¬"])

st.sidebar.markdown("---")
settings.similarity_threshold = st.sidebar.slider(
    "Out-of-scope ìœ ì‚¬ë„ ì„ê³„ì¹˜",
    min_value=0.00,
    max_value=1.00,
    value=float(settings.similarity_threshold),
    step=0.01,
    help="top1 similarityê°€ ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ 'ë¬¸ì„œì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.'",
)

# [ì¶”ê°€] ì´ë¯¸ì§€ ì¶•ì†Œ ìµœëŒ€ px ìŠ¬ë¼ì´ë” (OCR/í•´ì‹œ/ë¯¸ë¦¬ë³´ê¸° ê³µí†µ ì ìš©)
resize_max_px = st.sidebar.slider(
    "ì´ë¯¸ì§€ ì¶•ì†Œ ìµœëŒ€ px",
    min_value=512,
    max_value=2048,
    value=1024,
    step=64,
    help="ì—…ë¡œë“œ ì´ë¯¸ì§€ì˜ ê¸´ ë³€ì„ ì´ ê°’ ì´í•˜ë¡œ ì¶•ì†Œí•©ë‹ˆë‹¤. (OCR ë¹„ìš©/ì†ë„ ìµœì í™”)",
)


# -------------------------
# Admin
# -------------------------
if mode == "ì§€ì‹ ìì‚° ê´€ë¦¬":
    st.subheader("ë§¤ë‰´ì–¼ ì—…ë¡œë“œ ë° AI ì§€ì‹ ì—”ì§„ êµ¬ì¶•")

    title = st.text_input("ë¬¸ì„œ ì œëª©(ì˜ˆ: ì¥ë¹„A_ë§¤ë‰´ì–¼)", value="")
    pdf = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])

    if st.button("ì ì¬ ì‹¤í–‰", type="primary", disabled=not (title and pdf)):
        with st.spinner("PDFë¥¼ í˜ì´ì§€ë³„ë¡œ ì²˜ë¦¬í•˜ê³ , ì„ë² ë”©ì„ ìƒì„±í•˜ì—¬ Supabaseì— ì €ì¥ ì¤‘..."):
            pdf_bytes = pdf.read()
            doc_id, total_chunks = ingest_pdf_to_supabase(settings, pdf_bytes, title)
        st.success(f"ì™„ë£Œ! doc_id={doc_id}, total_chunks={total_chunks}")
        st.info("â€» ëª©ì°¨ ì œì™¸(DBë ˆë²¨)ëŠ” is_toc íƒœê¹…ì´ í•„ìš”í•˜ë¯€ë¡œ, ì´ ë°©ì‹ ì ìš© í›„ì—ëŠ” ì¬ì ì¬ê°€ ë°˜ì˜ë©ë‹ˆë‹¤.")

    st.divider()
    st.subheader("ì ì¬ëœ ë¬¸ì„œ ëª©ë¡")
    docs = list_docs(settings)
    if not docs:
        st.info("ì•„ì§ ì ì¬ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for d in docs:
            st.write(f"- #{d['id']} | {d['title']} | {d['created_at']}")

    st.divider()
    st.subheader("ë¬¸ì„œ ì‚­ì œ (DB + Storage ì´ë¯¸ì§€)")

    docs = list_docs(settings)
    if not docs:
        st.info("ì‚­ì œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        doc_map = {f"#{d['id']} - {d['title']}": int(d["id"]) for d in docs}
        sel_label = st.selectbox("ì‚­ì œí•  ë¬¸ì„œ ì„ íƒ", options=list(doc_map.keys()))
        del_doc_id = doc_map[sel_label]

        confirm = st.checkbox("ì •ë§ ì‚­ì œí•©ë‹ˆë‹¤. (DB + Storage ì´ë¯¸ì§€ê¹Œì§€ ì‚­ì œë¨)", value=False)
        if st.button("ì„ íƒ ë¬¸ì„œ ì‚­ì œ", type="secondary", disabled=not confirm):
            with st.spinner(f"doc_id={del_doc_id} ì‚­ì œ ì¤‘..."):
                result = delete_doc_and_assets(settings, del_doc_id)

            if result.get("ok"):
                st.success(f"ì‚­ì œ ì™„ë£Œ: doc_id={del_doc_id}")
                st.write(f"- Storage ì‚­ì œ: {result.get('storage_deleted', 0)}ê°œ")
                failed = result.get("storage_failed", [])
                if failed:
                    st.warning(f"Storage ì‚­ì œ ì‹¤íŒ¨ {len(failed)}ê°œ (ê¶Œí•œ/ê²½ë¡œ í™•ì¸ í•„ìš”)")
                    st.text("\n".join(failed[:50]))
            else:
                st.error(f"ì‚­ì œ ì‹¤íŒ¨: {result.get('error')}")

# -------------------------
# Chatbot
# -------------------------
else:
    st.subheader("í˜„ì¥ ì§ˆë¬¸í†¡")

    docs = list_docs(settings)
    doc_options = [{"id": None, "title": "ì „ì²´ ë¬¸ì„œ(ëª¨ë“  ë§¤ë‰´ì–¼)"}] + [
        {"id": int(d["id"]), "title": f"#{d['id']} - {d['title']}"}
        for d in docs
    ]
    selected = st.selectbox(
        "ê²€ìƒ‰ ë²”ìœ„(ë¬¸ì„œ ì„ íƒ)",
        options=doc_options,
        format_func=lambda x: x["title"],
        index=0,
    )
    doc_id_filter = selected["id"]

   

    # âœ… OCR / draft ìƒíƒœ
    if "draft_question" not in st.session_state:
        st.session_state.draft_question = "ì§ˆë¬¸ ì…ë ¥ (OCR ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤. ìˆ˜ì • í›„ ì „ì†¡í•˜ì„¸ìš”.)"
    if "ocr_image_signature" not in st.session_state:
        st.session_state.ocr_image_signature = None  # ë§ˆì§€ë§‰ OCR ìˆ˜í–‰í•œ ì´ë¯¸ì§€ ì‹ë³„ì
    if "ocr_text" not in st.session_state:
        st.session_state.ocr_text = ""
    if "last_audio_bytes" not in st.session_state:
        st.session_state.last_audio_bytes = None
    if "transcription_result" not in st.session_state:
        st.session_state.transcription_result = None
    if "finish_voice" not in st.session_state:
        st.session_state.finish_voice = False

     # ì±„íŒ… íˆìŠ¤í† ë¦¬
    if "chat" not in st.session_state:
        st.session_state.chat = []
    for msg in st.session_state.chat:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if msg["role"] == "assistant" and msg.get("pages"):
                render_related_pages(msg.get("pages"))



    # -------------------------
    # ì§ˆë¬¸ ì…ë ¥ / ì „ì†¡ (OCRê³¼ ë¬´ê´€: ì§ˆë¬¸ì°½ ë‚´ìš©ë§Œ ì „ì†¡)
    # -------------------------
    print(f"st.session_state.draft_question:{st.session_state.draft_question}")
    prompt = st.chat_input(
       st.session_state.draft_question
    )

    col1, col2, space = st.columns([0.07, 0.33, 0.6], vertical_alignment ="bottom")
    with col1:
        audio_bytes = audio_recorder(
            text="",
            recording_color="#e74c3c",
            neutral_color="#3498db",
            icon_name="microphone",
            icon_size="3x",
            pause_threshold=2.0,
            key="audio_recorder"
        )

    with col2:
        img_file = st.file_uploader(
                "ğŸ“· ì¥ë¹„ í™”ë©´ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œ (ì—…ë¡œë“œ ì‹œ ìë™ OCR, ì§ˆë¬¸ ì „ì†¡ê³¼ ë¬´ê´€)",
                type=["png", "jpg", "jpeg"],
                accept_multiple_files=False,
            )
        # col3, col4, col5 = st.columns([6, 3, 2])
        # # -------------------------
        # # ì´ë¯¸ì§€ ì—…ë¡œë“œ â†’ ìë™ OCR (ìƒˆ ì´ë¯¸ì§€ì¼ ë•Œë§Œ 1íšŒ)
        # # -------------------------
        # with col3:
        #     st.markdown("### ğŸ“· ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì—…ë¡œë“œ ì‹œ ìë™ OCR, ì§ˆë¬¸ ì „ì†¡ê³¼ ë¬´ê´€)")
        # with col4:
        #     img_file = st.file_uploader(
        #         "ğŸ“· ì¥ë¹„ í™”ë©´ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œ (ì—…ë¡œë“œ ì‹œ ìë™ OCR, ì§ˆë¬¸ ì „ì†¡ê³¼ ë¬´ê´€)",
        #         type=["png", "jpg", "jpeg"],
        #         accept_multiple_files=False,
        #     )
        # with col5:
        #     pass
    with space:
            # ì•„ë¬´ê²ƒë„ ì‘ì„±í•˜ì§€ ì•Šìœ¼ë©´ ë¹ˆ ê³µê°„ìœ¼ë¡œ ë‚¨ìŠµë‹ˆë‹¤.
        pass
    # print("0 start")
    # if audio_bytes and audio_bytes != st.session_state.last_audio_bytes:
    #      print("1 ë…¹ìŒ ì™„ë£Œ")
    # elif st.session_state.last_audio_bytes:
    #     print("1 ë…¹ìŒ ì™„ë£Œ")

    # ë³€í™˜ ì²˜ë¦¬
    if audio_bytes and audio_bytes != st.session_state.last_audio_bytes:
        st.session_state.last_audio_bytes = audio_bytes
        st.session_state.transcription_result = None  # ì´ì „ ê²°ê³¼ ì´ˆê¸°í™”
        print("1 ë…¹ìŒ ì €ì¥")
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(st.session_state.last_audio_bytes)
            wav_path = tmp_file.name
        try:
            # Whisper API í˜¸ì¶œ
            with st.spinner("ğŸ¤– ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                with open(wav_path, "rb") as audio_file:
                    client = get_openai_client(settings.openai_api_key)
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language="ko",
                        response_format="text"
                    )
        
            # ê²°ê³¼ ì €ì¥
            st.session_state.transcription_result = transcript
            print(f"ìŒì„±ë³€í™˜: {transcript}")
        
        except Exception as e:
            st.error(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
            st.exception(e)
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            try:
                if os.path.exists(wav_path):
                    os.remove(wav_path)
            except Exception:
                pass
    
    # 5. ì‹¤ì œ ì§ˆë¬¸ ê²°ì •
    final_prompt = prompt or st.session_state.transcription_result 
    if final_prompt:
        print("ì§ˆë¬¸")   
        st.session_state.draft_question = ""

        st.session_state.chat.append({"role": "user", "content": final_prompt})
        with st.chat_message("user"):
            st.markdown(final_prompt)

        with st.chat_message("assistant"):
            with st.spinner("ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
                result = process_rag_query(settings, final_prompt, doc_id_filter)
                answer = result["answer"]
                related_pages = result["related_pages"]
                resolved_doc_id = result["resolved_doc_id"]
                top1_similarity = result["top1_similarity"]
                # # ìœ ì‚¬ë„ ì •ë³´ í‘œì‹œ
                # st.caption(f"top1 similarity = {top1_similarity:.3f} (threshold={settings.similarity_threshold:.2f})")
                
                # ë‹µë³€ ì¶œë ¥
                # st.markdown(answer)
            pages = get_related_pages(
                settings=settings,
                resolved_doc_id=resolved_doc_id,
                related_pages=related_pages
            )
            # render_related_pages(pages)
        st.session_state.chat.append({
            "role": "assistant",
            "content": answer,
            "pages": pages
        })
        st.session_state.draft_question = final_prompt
        st.session_state.transcription_result = None
        st.rerun()
    
    if img_file: 
        print("ì´ë¯¸ì§€")   
        img_bytes = img_file.getvalue()
        mime = img_file.type or "image/png"
        if len(st.session_state.ocr_text) > 0:
            question = st.text_input(
                "OCR ì§ˆë¬¸",
                value=st.session_state.ocr_text
            )

        # ë¯¸ë¦¬ë³´ê¸°
        # col1, col2 = st.columns([1, 7], gap="medium")
        # with col1:
        #     st.image(img_bytes, caption="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€")
        # with col2:
        #     if len(st.session_state.ocr_text) > 0:
        #         question = st.text_input(
        #             "OCR ì§ˆë¬¸",
        #             value=st.session_state.ocr_text
        #         )
        #         # if st.button("ì´ ì§ˆë¬¸ìœ¼ë¡œ ì „ì†¡"):
        #         #     print("ì „ì†¡")
        #     else:
        #         pass
                

        # âœ… ìµœëŒ€ 1024pxë¡œ ìë™ ì¶•ì†Œ (ë¹„ìœ¨ ìœ ì§€)
        try:
            pil_img = Image.open(BytesIO(img_bytes))
            pil_img.thumbnail((resize_max_px, resize_max_px), Image.LANCZOS)

            buf = BytesIO()
            # ì›ë³¸ í¬ë§·ì„ ìµœëŒ€í•œ ìœ ì§€ (ì—†ìœ¼ë©´ PNG)
            save_format = (pil_img.format or "PNG").upper()
            if save_format not in ("PNG", "JPEG", "JPG", "WEBP"):
                save_format = "PNG"

            # JPEGë¡œ ì €ì¥í•  ë•ŒëŠ” RGB í•„ìš”í•  ìˆ˜ ìˆìŒ
            if save_format in ("JPEG", "JPG") and pil_img.mode in ("RGBA", "P"):
                pil_img = pil_img.convert("RGB")

            pil_img.save(buf, format=save_format)
            img_bytes = buf.getvalue()  # âœ… ì´í›„ ë¡œì§(OCR/ë¯¸ë¦¬ë³´ê¸°/í•´ì‹œ)ì— ì¶•ì†Œë³¸ì„ ì‚¬ìš©
        except Exception:
            # ì¶•ì†Œ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€
            pass

        # âœ… ë‚´ìš© ê¸°ë°˜ ì‹œê·¸ë‹ˆì²˜(í•´ì‹œ): rerun(ì§ˆë¬¸ ì „ì†¡)ì—ë„ ë™ì¼ ì´ë¯¸ì§€ë©´ OCR ì¬ì‹¤í–‰ ì•ˆ í•¨
        digest = hashlib.sha256(img_bytes).hexdigest()
        image_signature = f"{digest}"

        # âœ… ìƒˆ ì´ë¯¸ì§€ì¼ ë•Œë§Œ OCR ì‹¤í–‰
        if st.session_state.ocr_image_signature != image_signature:
            with st.spinner("ì´ë¯¸ì§€ì—ì„œ ë¬¸ì ì¶”ì¶œ ì¤‘ (gpt-4.1-mini)..."):
                oai = get_openai_client(settings.openai_api_key)
                ocr_text = extract_text_from_image_gpt41mini(oai, img_bytes, mime)

            st.session_state.ocr_image_signature = image_signature
            st.session_state.ocr_text = (ocr_text or "").strip()

            if st.session_state.ocr_text:
                # âœ… OCR ê²°ê³¼ë¥¼ ì§ˆë¬¸ì°½ìœ¼ë¡œ ë³´ë‚´ê¸°(ìë™ ì§ˆë¬¸ ì „ì†¡ X)
                st.session_state.draft_question = st.session_state.ocr_text
                st.success("OCR ì™„ë£Œ: ì§ˆë¬¸ ì…ë ¥ì°½ì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤. í•„ìš”í•˜ë©´ ìˆ˜ì • í›„ ì „ì†¡í•˜ì„¸ìš”.")
                st.rerun()
            else:
                st.warning("OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ í•´ìƒë„/ì„ ëª…ë„ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")

