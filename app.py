import hashlib
import streamlit as st

from config import load_settings
from clients import get_openai_client
from ocr_service import extract_text_from_image_gpt41mini
from ingest_service import ingest_pdf_to_supabase
from retrieval_service import retrieve_contexts, list_docs, get_page_image_url
from answer_service import openai_answer_with_rag
from storage_service import delete_doc_and_assets
from utils_text import is_refusal_answer, merge_pages_cited_then_search

from audio_recorder_streamlit import audio_recorder
import os
import tempfile
from process_rag_query import process_rag_query

st.set_page_config(page_title="PDF ë§¤ë‰´ì–¼ RAG ì±—ë´‡", layout="wide")
settings = load_settings()

st.title("ğŸ“˜ PDF ë§¤ë‰´ì–¼ RAG ì±—ë´‡ (Supabase + OpenAI)")

if not settings.openai_api_key or not settings.supabase_url or not settings.supabase_service_key:
    st.warning(
        "í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤!\n\n"
        "- OPENAI_API_KEY\n"
        "- SUPABASE_URL\n"
        "- SUPABASE_SERVICE_ROLE_KEY\n"
    )
    st.stop()

mode = st.sidebar.radio("ë©”ë‰´", ["ê´€ë¦¬ì: PDF ì—…ë¡œë“œ/ì ì¬", "ì‚¬ìš©ì: ì±—ë´‡"])

st.sidebar.markdown("---")
settings.similarity_threshold = st.sidebar.slider(
    "Out-of-scope ìœ ì‚¬ë„ ì„ê³„ì¹˜(ë†’ì„ìˆ˜ë¡ ì—„ê²©)",
    min_value=0.00,
    max_value=1.00,
    value=float(settings.similarity_threshold),
    step=0.01,
    help="top1 similarityê°€ ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ 'ë¬¸ì„œì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.'",
)

# -------------------------
# Admin
# -------------------------
if mode == "ê´€ë¦¬ì: PDF ì—…ë¡œë“œ/ì ì¬":
    st.subheader("ê´€ë¦¬ì: PDF ì—…ë¡œë“œ ë° RAG ì ì¬")

    title = st.text_input("ë¬¸ì„œ ì œëª©(ì˜ˆ: ì¥ë¹„A_ë§¤ë‰´ì–¼)", value="")
    pdf = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])

    if st.button("ì ì¬ ì‹¤í–‰", type="primary", disabled=not (title and pdf)):
        with st.spinner("PDFë¥¼ í˜ì´ì§€ë³„ë¡œ ì²˜ë¦¬í•˜ê³ , ì„ë² ë”©ì„ ìƒì„±í•˜ì—¬ Supabaseì— ì €ì¥ ì¤‘..."):
            pdf_bytes = pdf.read()
            doc_id, total_chunks = ingest_pdf_to_supabase(settings, pdf_bytes, title)
        st.success(f"ì™„ë£Œ! doc_id={doc_id}, total_chunks={total_chunks}")
        st.info("â€» ëª©ì°¨ ì œì™¸(DBë ˆë²¨)ëŠ” is_toc íƒœê¹…ì´ í•„ìš”í•˜ë¯€ë¡œ, ì´ ë°©ì‹ ì ìš© í›„ì—ëŠ” ì¬ì ì¬ê°€ ë°˜ì˜ë©ë‹ˆë‹¤.")

    st.divider()
    st.subheader("ì ì¬ëœ ë¬¸ì„œ ëª©ë¡")
    docs = list_docs(settings)
    if not docs:
        st.info("ì•„ì§ ì ì¬ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for d in docs:
            st.write(f"- #{d['id']} | {d['title']} | {d['created_at']}")

    st.divider()
    st.subheader("ë¬¸ì„œ ì‚­ì œ (DB + Storage ì´ë¯¸ì§€)")

    docs = list_docs(settings)
    if not docs:
        st.info("ì‚­ì œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        doc_map = {f"#{d['id']} - {d['title']}": int(d["id"]) for d in docs}
        sel_label = st.selectbox("ì‚­ì œí•  ë¬¸ì„œ ì„ íƒ", options=list(doc_map.keys()))
        del_doc_id = doc_map[sel_label]

        confirm = st.checkbox("ì •ë§ ì‚­ì œí•©ë‹ˆë‹¤. (DB + Storage ì´ë¯¸ì§€ê¹Œì§€ ì‚­ì œë¨)", value=False)
        if st.button("ì„ íƒ ë¬¸ì„œ ì‚­ì œ", type="secondary", disabled=not confirm):
            with st.spinner(f"doc_id={del_doc_id} ì‚­ì œ ì¤‘..."):
                result = delete_doc_and_assets(settings, del_doc_id)

            if result.get("ok"):
                st.success(f"ì‚­ì œ ì™„ë£Œ: doc_id={del_doc_id}")
                st.write(f"- Storage ì‚­ì œ: {result.get('storage_deleted', 0)}ê°œ")
                failed = result.get("storage_failed", [])
                if failed:
                    st.warning(f"Storage ì‚­ì œ ì‹¤íŒ¨ {len(failed)}ê°œ (ê¶Œí•œ/ê²½ë¡œ í™•ì¸ í•„ìš”)")
                    st.text("\n".join(failed[:50]))
            else:
                st.error(f"ì‚­ì œ ì‹¤íŒ¨: {result.get('error')}")

# -------------------------
# Chatbot
# -------------------------
else:
    st.subheader("ì‚¬ìš©ì: ë§¤ë‰´ì–¼ Q&A")

    docs = list_docs(settings)
    doc_options = [{"id": None, "title": "ì „ì²´ ë¬¸ì„œ(ëª¨ë“  ë§¤ë‰´ì–¼)"}] + [
        {"id": int(d["id"]), "title": f"#{d['id']} - {d['title']}"}
        for d in docs
    ]
    selected = st.selectbox(
        "ê²€ìƒ‰ ë²”ìœ„(ë¬¸ì„œ ì„ íƒ)",
        options=doc_options,
        format_func=lambda x: x["title"],
        index=0,
    )
    doc_id_filter = selected["id"]

    # ì±„íŒ… íˆìŠ¤í† ë¦¬
    if "chat" not in st.session_state:
        st.session_state.chat = []
    for msg in st.session_state.chat:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # âœ… OCR / draft ìƒíƒœ
    if "draft_question" not in st.session_state:
        st.session_state.draft_question = ""
    if "ocr_image_signature" not in st.session_state:
        st.session_state.ocr_image_signature = None  # ë§ˆì§€ë§‰ OCR ìˆ˜í–‰í•œ ì´ë¯¸ì§€ ì‹ë³„ì
    if "ocr_text" not in st.session_state:
        st.session_state.ocr_text = ""
    if "last_audio_bytes" not in st.session_state:
        st.session_state.last_audio_bytes = None
    if "transcription_result" not in st.session_state:
        st.session_state.transcription_result = None


    # -------------------------
    # ì´ë¯¸ì§€ ì—…ë¡œë“œ â†’ ìë™ OCR (ìƒˆ ì´ë¯¸ì§€ì¼ ë•Œë§Œ 1íšŒ)
    # -------------------------
    st.markdown("### ğŸ“· ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì—…ë¡œë“œ ì‹œ ìë™ OCR, ì§ˆë¬¸ ì „ì†¡ê³¼ ë¬´ê´€)")
    img_file = st.file_uploader(
        "ì¥ë¹„ í™”ë©´ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (png/jpg/jpeg)",
        type=["png", "jpg", "jpeg"],
        accept_multiple_files=False,
    )

    if img_file:
        img_bytes = img_file.getvalue()
        mime = img_file.type or "image/png"

        # ë¯¸ë¦¬ë³´ê¸°
        st.image(img_bytes, caption="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€", width=350)

        # âœ… ë‚´ìš© ê¸°ë°˜ ì‹œê·¸ë‹ˆì²˜(í•´ì‹œ): rerun(ì§ˆë¬¸ ì „ì†¡)ì—ë„ ë™ì¼ ì´ë¯¸ì§€ë©´ OCR ì¬ì‹¤í–‰ ì•ˆ í•¨
        digest = hashlib.sha256(img_bytes).hexdigest()
        image_signature = f"{digest}"

        # âœ… ìƒˆ ì´ë¯¸ì§€ì¼ ë•Œë§Œ OCR ì‹¤í–‰
        if st.session_state.ocr_image_signature != image_signature:
            with st.spinner("ì´ë¯¸ì§€ì—ì„œ ë¬¸ì ì¶”ì¶œ ì¤‘ (gpt-4.1-mini)..."):
                oai = get_openai_client(settings.openai_api_key)
                ocr_text = extract_text_from_image_gpt41mini(oai, img_bytes, mime)

            st.session_state.ocr_image_signature = image_signature
            st.session_state.ocr_text = (ocr_text or "").strip()

            if st.session_state.ocr_text:
                # âœ… OCR ê²°ê³¼ë¥¼ ì§ˆë¬¸ì°½ìœ¼ë¡œ ë³´ë‚´ê¸°(ìë™ ì§ˆë¬¸ ì „ì†¡ X)
                st.session_state.draft_question = st.session_state.ocr_text
                st.success("OCR ì™„ë£Œ: ì§ˆë¬¸ ì…ë ¥ì°½ì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤. í•„ìš”í•˜ë©´ ìˆ˜ì • í›„ ì „ì†¡í•˜ì„¸ìš”.")
            else:
                st.warning("OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ í•´ìƒë„/ì„ ëª…ë„ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")

    # -------------------------
    # ì§ˆë¬¸ ì…ë ¥ / ì „ì†¡ (OCRê³¼ ë¬´ê´€: ì§ˆë¬¸ì°½ ë‚´ìš©ë§Œ ì „ì†¡)
    # -------------------------
    question = st.text_area(
        "ì§ˆë¬¸ ì…ë ¥ (OCR ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤. ìˆ˜ì • í›„ ì „ì†¡í•˜ì„¸ìš”.)",
        value=st.session_state.draft_question,
        height=120,
    )

    col1, col2, space = st.columns([2, 0.8, 5])
    with col1:
        send = st.button(
            "ì§ˆë¬¸ ì „ì†¡", 
            type="primary", 
            disabled=not question.strip() if question else True,
            use_container_width=True
        )

    with col2:
       audio_bytes = audio_recorder(
            text="",
            recording_color="#e74c3c",
            neutral_color="#3498db",
            icon_name="microphone",
            icon_size="3x",
            pause_threshold=2.0,
            key="audio_recorder"
        )

    with space:
        # ì•„ë¬´ê²ƒë„ ì‘ì„±í•˜ì§€ ì•Šìœ¼ë©´ ë¹ˆ ê³µê°„ìœ¼ë¡œ ë‚¨ìŠµë‹ˆë‹¤.
        pass

    if send:
        # ì „ì†¡ì€ ì§ˆë¬¸ì°½ ë‚´ìš©ë§Œ ì‚¬ìš© (OCR ì¬ì‹¤í–‰ê³¼ ë¬´ê´€)
        st.session_state.draft_question = ""

        st.session_state.chat.append({"role": "user", "content": question})
        with st.chat_message("user"):
            st.markdown(question)

        with st.chat_message("assistant"):
            with st.spinner("ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
                contexts, top1_similarity = retrieve_contexts(settings, question, doc_id_filter=doc_id_filter)
                st.caption(f"top1 similarity = {top1_similarity:.3f} (threshold={settings.similarity_threshold:.2f})")

                out_of_scope = (not contexts) or (top1_similarity < settings.similarity_threshold)
                cited_pages = []

                if out_of_scope:
                    answer = "ë¬¸ì„œì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                else:
                    oai = get_openai_client(settings.openai_api_key)
                    out = openai_answer_with_rag(oai, settings.chat_model, question, contexts)
                    answer = out["answer"]
                    cited_pages = out.get("cited_pages", [])

                    # ë³´ìˆ˜ì ìœ¼ë¡œ í•œ ë²ˆ ë” ì°¨ë‹¨ (ì• ë§¤í•œ ê²½ìš°)
                    if ("ë¬¸ì„œì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤" not in answer) and (top1_similarity < (settings.similarity_threshold + 0.02)):
                        answer = "ë¬¸ì„œì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                        cited_pages = []

                st.markdown(answer)

                # ê´€ë ¨ í˜ì´ì§€: ê±°ì ˆë‹µë³€ì´ë©´ ì ˆëŒ€ í‘œì‹œí•˜ì§€ ì•ŠìŒ
                if is_refusal_answer(answer):
                    related_pages = []
                    resolved_doc_id = None
                else:
                    related_pages = merge_pages_cited_then_search(
                        cited_pages=cited_pages,
                        contexts=contexts,
                        max_pages=settings.max_related_pages,
                        top1_similarity=top1_similarity,
                        min_abs=0.35,
                        max_drop=0.08,
                    )
                    resolved_doc_id = (
                        doc_id_filter if doc_id_filter is not None
                        else (int(contexts[0]["doc_id"]) if contexts else None)
                    )

                # ê´€ë ¨ í˜ì´ì§€ 3+3 (ìµœëŒ€ 6)
                if resolved_doc_id and related_pages:
                    st.caption("ê´€ë ¨ í˜ì´ì§€ (ìµœëŒ€ 6í˜ì´ì§€, í˜ì´ì§€ ìˆœ)")

                    row1 = related_pages[:3]
                    cols1 = st.columns(3)
                    for idx in range(3):
                        with cols1[idx]:
                            if idx < len(row1):
                                p = row1[idx]
                                url = get_page_image_url(settings, resolved_doc_id, int(p))
                                if url:
                                    st.image(url, caption=f"p.{p}", width="stretch")
                                else:
                                    st.write(f"p.{p} ì´ë¯¸ì§€ ì—†ìŒ")

                    row2 = related_pages[3:6]
                    if row2:
                        cols2 = st.columns(3)
                        for idx in range(3):
                            with cols2[idx]:
                                if idx < len(row2):
                                    p = row2[idx]
                                    url = get_page_image_url(settings, resolved_doc_id, int(p))
                                    if url:
                                        st.image(url, caption=f"p.{p}", width="stretch")
                                    else:
                                        st.write(f"p.{p} ì´ë¯¸ì§€ ì—†ìŒ")

        st.session_state.chat.append({"role": "assistant", "content": answer})

    
    if audio_bytes and audio_bytes != st.session_state.last_audio_bytes:
        st.session_state.last_audio_bytes = audio_bytes
        st.session_state.transcription_result = None  # ì´ì „ ê²°ê³¼ ì´ˆê¸°í™”
        print("1 ë…¹ìŒ ì™„ë£Œ")
    elif st.session_state.last_audio_bytes:
        print("2 ë…¹ìŒ ì™„ë£Œ")

    # ë³€í™˜ ì²˜ë¦¬
    if st.session_state.last_audio_bytes and not st.session_state.transcription_result:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(st.session_state.last_audio_bytes)
            wav_path = tmp_file.name
        try:
            # Whisper API í˜¸ì¶œ
            with st.spinner("ğŸ¤– ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                with open(wav_path, "rb") as audio_file:
                    client = get_openai_client(settings.openai_api_key)
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language="ko",
                        response_format="text"
                    )
        
            # ê²°ê³¼ ì €ì¥
            st.session_state.transcription_result = transcript
            print(f"ìŒì„±ë³€í™˜: {transcript}")

            st.session_state.draft_question = ""
            st.session_state.chat.append({"role": "user", "content": transcript})
    
            with st.chat_message("user"):
                st.markdown(transcript)

            with st.chat_message("assistant"):
                with st.spinner("ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
                    # ìœ„ì—ì„œ ë§Œë“  í•¨ìˆ˜ í˜¸ì¶œ
                    result = process_rag_query(settings, transcript, doc_id_filter)
                    
                    answer = result["answer"]
                    related_pages = result["related_pages"]
                    resolved_doc_id = result["resolved_doc_id"]
                    top1_similarity = result["top1_similarity"]

                    # ìœ ì‚¬ë„ ì •ë³´ í‘œì‹œ
                    st.caption(f"top1 similarity = {top1_similarity:.3f} (threshold={settings.similarity_threshold:.2f})")
                    
                    # ë‹µë³€ ì¶œë ¥
                    st.markdown(answer)

                # ê´€ë ¨ í˜ì´ì§€ ì´ë¯¸ì§€ ì¶œë ¥ (UI ë¡œì§)
                if resolved_doc_id and related_pages:
                    st.caption("ê´€ë ¨ í˜ì´ì§€ (ìµœëŒ€ 6í˜ì´ì§€, í˜ì´ì§€ ìˆœ)")
            
                    # í˜ì´ì§€ë¥¼ 3ê°œì”© ëŠì–´ì„œ ì²˜ë¦¬
                    for i in range(0, len(related_pages), 3):
                        row_pages = related_pages[i : i + 3]
                        cols = st.columns(3)
                        for idx, p in enumerate(row_pages):
                            with cols[idx]:
                                url = get_page_image_url(settings, resolved_doc_id, int(p))
                                if url:
                                    st.image(url, caption=f"p.{p}", use_container_width=True) # width="stretch" ëŒ€ì‹  ìµœì‹  ë¬¸ë²• ì‚¬ìš©
                                else:
                                    st.write(f"p.{p} ì´ë¯¸ì§€ ì—†ìŒ")

            st.session_state.chat.append({"role": "assistant", "content": answer})
        
        except Exception as e:
            st.error(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
            st.exception(e)
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            try:
                if os.path.exists(wav_path):
                    os.remove(wav_path)
            except Exception:
                pass